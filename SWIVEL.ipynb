{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWIVEL(Sub-matrix Wise Vector Embedding Learner)\n",
    "\n",
    "1. Word2Vec and GloVe\n",
    "2. Co-occurance Matrix\n",
    "3. Sharding Cooccurance Matrix \n",
    "4. Distributed Learning\n",
    "5. Result\n",
    "6. Application in Ecommerce, product Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1. Data preparation from raw corpus \n",
    "- prerequisite:\n",
    "  For large vocabulary size, should increase the numeberf of open-files \n",
    "  https://easyengine.io/tutorials/linux/increase-open-files-limit/\n",
    "- Python: too slow, use C++ Code.\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fastprep --input ~/wiki-data/kowiki.txt\\\n",
      "\t--output_dir data_prep\\\n",
      "        --max_vocab 200000\\\n",
      "\t--num_threads 16\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ./run_prep.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./run_prep.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python SWIVEL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submatrix-wise Vector Embedding Learner.\n",
      "\n",
      "Implementation of SwiVel algorithm described at:\n",
      "http://arxiv.org/abs/1602.02215\n",
      "\n",
      "This program expects an input directory that contains the following files.\n",
      "\n",
      "  row_vocab.txt, col_vocab.txt\n",
      "\n",
      "    The row an column vocabulary files.  Each file should contain one token per\n",
      "    line; these will be used to generate a tab-separate file containing the\n",
      "    trained embeddings.\n",
      "\n",
      "  row_sums.txt, col_sum.txt\n",
      "\n",
      "    The matrix row and column marginal sums.  Each file should contain one\n",
      "    decimal floating point number per line which corresponds to the marginal\n",
      "    count of the matrix for that row or column.\n",
      "\n",
      "  shards.recs\n",
      "\n",
      "    A file containing the sub-matrix shards, stored as TFRecords.  Each shard is\n",
      "    expected to be a serialzed tf.Example protocol buffer with the following\n",
      "    properties:\n",
      "\n",
      "      global_row: the global row indicies contained in the shard\n",
      "      global_col: the global column indicies contained in the shard\n",
      "      sparse_local_row, sparse_local_col, sparse_value: three parallel arrays\n",
      "      that are a sparse representation of the submatrix counts.\n",
      "\n",
      "It will generate embeddings, training from the input directory for the specified\n",
      "number of epochs.  When complete, it will output the trained vectors to a\n",
      "tab-separated file that contains one line per embedding.  Row and column\n",
      "embeddings are stored in separate files.\n",
      "\n",
      "Swivel can be run \"stand-alone\" or \"distributed\".  The latter involves running\n",
      "at least one parameter server process, along with one or more worker processes.\n",
      "\n",
      "flags:\n",
      "\n",
      "./swivel.py:\n",
      "  --confidence_base: Base for count weighting\n",
      "    (default: '0.0')\n",
      "    (a number)\n",
      "  --confidence_exponent: Exponent for count weighting\n",
      "    (default: '0.5')\n",
      "    (a number)\n",
      "  --confidence_scale: Scale for count weighting\n",
      "    (default: '1.0')\n",
      "    (a number)\n",
      "  --dim: Embedding dimensionality\n",
      "    (default: '300')\n",
      "    (an integer)\n",
      "  --eval_base_path: Path to evaluation data\n",
      "    (default: '')\n",
      "  --gpu_device: The GPU device to use.\n",
      "    (default: '0')\n",
      "    (an integer)\n",
      "  --hparams: Model hyper-parameters\n",
      "    (default: '')\n",
      "  --input_base_path: Directory containing input shards, vocabularies, and\n",
      "    marginals.\n",
      "    (default: '/tmp/swivel_data')\n",
      "  --job_name: The job this process will run, either \"ps\" or \"worker\"\n",
      "    (default: '')\n",
      "  --learning_rate: Optimizer learning rate\n",
      "    (default: '0.1')\n",
      "    (a number)\n",
      "  --momentum: Optimizer momentum; used with RMSProp\n",
      "    (default: '0.1')\n",
      "    (a number)\n",
      "  --num_epochs: Number epochs to train\n",
      "    (default: '40.0')\n",
      "    (a number)\n",
      "  --optimizer: SGD optimizer; either \"adagrad\" or \"rmsprop\"\n",
      "    (default: 'rmsprop')\n",
      "  --output_base_path: Path where to write the trained embeddings.\n",
      "    (default: '/tmp/swivel_data')\n",
      "  --ps_hosts: Comma-separated list of parameter server host:port; if empty, run\n",
      "    local\n",
      "    (default: '')\n",
      "  --submatrix_cols: Number of cols in each submatrix\n",
      "    (default: '4096')\n",
      "    (an integer)\n",
      "  --submatrix_rows: Number of rows in each submatrix\n",
      "    (default: '4096')\n",
      "    (an integer)\n",
      "  --task_index: The task index for this process\n",
      "    (default: '0')\n",
      "    (an integer)\n",
      "  --worker_hosts: Comma-separated list of worker host:port\n",
      "    (default: '')\n",
      "\n",
      "Try --helpfull to get a list of all flags.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python2 ./swivel.py --help "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./swivel.py --input_base_path data_prep \\\n",
      "   --output_base_path result\\\n",
      "   --worker-hosts 16\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ./run_swivel.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Words Vectors as a Binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "python2 text2bin.py -o embedding/vecs.bin -v embedding/vocab.txt result/*_embedding.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ./text2bin.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading trained Word Vectors(binary)\n",
    "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query> "
     ]
    }
   ],
   "source": [
    "%%bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
